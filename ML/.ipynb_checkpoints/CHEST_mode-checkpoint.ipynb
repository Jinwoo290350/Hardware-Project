{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall Detection â€” CHEST CLIP Mode\n",
    "**MPU6050 placement: Chest / Clip on shirt**\n",
    "\n",
    "---\n",
    "## ðŸ“Š Dataset Feasibility Analysis\n",
    "\n",
    "| Dataset | Placement | Falls | ADL | Accuracy (reported) | Download |\n",
    "|---------|-----------|-------|-----|--------------------|---------|\n",
    "| **SisFall** | Waist/Chest | 15 types Ã— 38 subjects | 19 types | 96-99% | http://sistemic.udea.edu.co/en/research/projects/sisfall |\n",
    "| **KFall** | Low back | 15 types Ã— 32 subjects | 21 types | 90%+ | https://sites.google.com/view/kfalldataset |\n",
    "| **MobiAct** | Pocket (smartphone) | 4 types Ã— 66 subjects | 12 types | 85-95% | https://bmi.hmu.gr/the-mobifall-and-mobiact-datasets-2/ |\n",
    "\n",
    "**Best choice for CHEST: SisFall** â€” Body-mounted sensor, closest to chest clip placement.\n",
    "Expected accuracy: **95â€“99%** (chest/waist is the most accurate position)\n",
    "\n",
    "### SisFall Data Format\n",
    "```\n",
    "Columns: ax, ay, az, gx, gy, gz  (accelerometer + gyroscope)\n",
    "Sampling rate: 200 Hz â†’ downsample to 50 Hz\n",
    "Files: F01_R01.txt to F15_R05.txt (falls) + D01_R01.txt (ADL)\n",
    "Label: F = fall (1), D = daily activity (0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats, signal\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# â”€â”€ Dependencies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats, signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PLACEMENT = 'CHEST'\n",
    "SAMPLE_RATE = 50        # Hz (downsample from 200 Hz SisFall)\n",
    "WINDOW_SIZE = 100       # 2 seconds @ 50 Hz\n",
    "STEP_SIZE   = 50        # 1 second overlap\n",
    "N_FEATURES  = 23\n",
    "RANDOM_STATE = 42\n",
    "print(f'Config: placement={PLACEMENT}, fs={SAMPLE_RATE}Hz, window={WINDOW_SIZE/SAMPLE_RATE}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "\n",
    "**à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸” SisFall à¸à¹ˆà¸­à¸™:**  \n",
    "1. à¹„à¸›à¸—à¸µà¹ˆ http://sistemic.udea.edu.co/en/research/projects/sisfall  \n",
    "2. Download ZIP â†’ à¹à¸•à¸à¹„à¸§à¹‰à¹ƒà¸™ `data/SisFall/`  \n",
    "3. à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡: `data/SisFall/SisFall_dataset/F01/F01_R01.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "DATA_DIR = 'data/SisFall/SisFall_dataset'\n",
    "\n",
    "def load_sisfall(data_dir: str):\n",
    "    \"\"\"Load SisFall CSV files â†’ DataFrame with label column.\"\"\"\n",
    "    records = []\n",
    "    for path in glob.glob(os.path.join(data_dir, '**', '*.txt'), recursive=True):\n",
    "        fname = os.path.basename(path)\n",
    "        label = 1 if fname.startswith('F') else 0   # F=fall, D=ADL\n",
    "        try:\n",
    "            df = pd.read_csv(path, header=None,\n",
    "                             names=['ax','ay','az','gx','gy','gz'])\n",
    "            # Downsample 200 Hz â†’ 50 Hz (keep every 4th row)\n",
    "            df = df.iloc[::4].reset_index(drop=True)\n",
    "            df['label'] = label\n",
    "            df['file']  = fname\n",
    "            records.append(df)\n",
    "        except Exception as e:\n",
    "            print(f'Skip {fname}: {e}')\n",
    "    if records:\n",
    "        return pd.concat(records, ignore_index=True)\n",
    "    raise FileNotFoundError(f'No data found in {data_dir}. Please download SisFall.')\n",
    "\n",
    "# â”€â”€â”€ Demo mode: generate synthetic data when real dataset not available â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_synthetic_data(n_fall=500, n_adl=1000, fs=50, seed=42):\n",
    "    \"\"\"Synthetic MPU6050-like signals for pipeline testing.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rows = []\n",
    "    for _ in range(n_adl):\n",
    "        t  = np.arange(WINDOW_SIZE) / fs\n",
    "        ax = rng.normal(0, 0.5, WINDOW_SIZE) + np.sin(2*np.pi*1*t)\n",
    "        ay = rng.normal(0, 0.5, WINDOW_SIZE)\n",
    "        az = rng.normal(9.8, 0.3, WINDOW_SIZE)    # gravity on Z\n",
    "        gx = rng.normal(0, 10, WINDOW_SIZE)\n",
    "        gy = rng.normal(0, 10, WINDOW_SIZE)\n",
    "        gz = rng.normal(0, 10, WINDOW_SIZE)\n",
    "        for i in range(WINDOW_SIZE):\n",
    "            rows.append([ax[i],ay[i],az[i],gx[i],gy[i],gz[i],0,'adl'])\n",
    "    for _ in range(n_fall):\n",
    "        t  = np.arange(WINDOW_SIZE) / fs\n",
    "        # Freefall: low magnitude then spike (impact)\n",
    "        ax = np.concatenate([rng.normal(0,0.2,30), rng.normal(20,5,10), rng.normal(0,0.5,60)])\n",
    "        ay = np.concatenate([rng.normal(0,0.2,30), rng.normal(15,5,10), rng.normal(0,0.5,60)])\n",
    "        az = np.concatenate([rng.normal(1,0.5,30), rng.normal(25,8,10), rng.normal(2,0.5,60)])\n",
    "        gx = np.concatenate([rng.normal(0,20,30),  rng.normal(300,50,10), rng.normal(0,20,60)])\n",
    "        gy = np.concatenate([rng.normal(0,20,30),  rng.normal(200,50,10), rng.normal(0,20,60)])\n",
    "        gz = np.concatenate([rng.normal(0,20,30),  rng.normal(100,30,10), rng.normal(0,20,60)])\n",
    "        for i in range(WINDOW_SIZE):\n",
    "            rows.append([ax[i],ay[i],az[i],gx[i],gy[i],gz[i],1,'fall'])\n",
    "    return pd.DataFrame(rows, columns=['ax','ay','az','gx','gy','gz','label','type'])\n",
    "\n",
    "# â”€â”€ Load real or synthetic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if os.path.exists(DATA_DIR):\n",
    "    raw = load_sisfall(DATA_DIR)\n",
    "    print(f'Loaded SisFall: {len(raw):,} rows')\n",
    "else:\n",
    "    print('âš ï¸  SisFall not found â†’ using SYNTHETIC data (for pipeline testing only)')\n",
    "    raw = make_synthetic_data()\n",
    "\n",
    "print(raw.head())\n",
    "print(f'Falls: {(raw.label==1).sum():,} | ADL: {(raw.label==0).sum():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Signal Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6))\n",
    "for ax_plot, label, color, title in zip(\n",
    "        axes, [0, 1], ['steelblue', 'crimson'], ['ADL (Normal)', 'FALL']):\n",
    "    sample = raw[raw['label'] == label].head(200)\n",
    "    mag = np.sqrt(sample['ax']**2 + sample['ay']**2 + sample['az']**2)\n",
    "    ax_plot.plot(mag.values, color=color)\n",
    "    ax_plot.set_title(f'{title} â€” Acceleration Magnitude  |  Placement: {PLACEMENT}')\n",
    "    ax_plot.set_ylabel('|acc| (m/sÂ²)')\n",
    "    ax_plot.set_xlabel('Sample')\n",
    "    ax_plot.axhline(3.0,  color='orange', ls='--', lw=1, label='freefall threshold')\n",
    "    ax_plot.axhline(20.0, color='red',    ls='--', lw=1, label='impact threshold')\n",
    "    ax_plot.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'models/{PLACEMENT}_signal.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction â€” 23 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_23_features(window: np.ndarray, fs: int = SAMPLE_RATE) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract 23 features from a (WINDOW_SIZE, 6) window [ax,ay,az,gx,gy,gz].\n",
    "    Feature index reference:\n",
    "      0-2  : mean ax, ay, az\n",
    "      3-5  : std  ax, ay, az\n",
    "      6    : min magnitude\n",
    "      7    : max magnitude\n",
    "      8    : range magnitude\n",
    "      9-11 : RMS ax, ay, az\n",
    "      12   : skewness of magnitude\n",
    "      13   : kurtosis  of magnitude\n",
    "      14   : zero-crossing count of magnitude\n",
    "      15   : SMA (signal magnitude area)\n",
    "      16   : dominant frequency (FFT)\n",
    "      17   : spectral energy\n",
    "      18-20: correlation ax-ay, ay-az, ax-az\n",
    "      21   : max jerk magnitude\n",
    "      22   : acceleration variance\n",
    "    \"\"\"\n",
    "    ax, ay, az = window[:, 0], window[:, 1], window[:, 2]\n",
    "    mag = np.sqrt(ax**2 + ay**2 + az**2)\n",
    "\n",
    "    # 0-2: mean per axis\n",
    "    f = [np.mean(ax), np.mean(ay), np.mean(az)]\n",
    "\n",
    "    # 3-5: std per axis\n",
    "    f += [np.std(ax), np.std(ay), np.std(az)]\n",
    "\n",
    "    # 6-8: magnitude stats\n",
    "    f += [np.min(mag), np.max(mag), np.ptp(mag)]\n",
    "\n",
    "    # 9-11: RMS per axis\n",
    "    f += [np.sqrt(np.mean(ax**2)), np.sqrt(np.mean(ay**2)), np.sqrt(np.mean(az**2))]\n",
    "\n",
    "    # 12-13: skewness, kurtosis of magnitude\n",
    "    f += [stats.skew(mag), stats.kurtosis(mag)]\n",
    "\n",
    "    # 14: zero-crossing count\n",
    "    mag_centered = mag - np.mean(mag)\n",
    "    f.append(np.sum(np.diff(np.sign(mag_centered)) != 0))\n",
    "\n",
    "    # 15: SMA\n",
    "    f.append(np.sum(np.abs(ax) + np.abs(ay) + np.abs(az)) / len(ax))\n",
    "\n",
    "    # 16-17: FFT dominant frequency + spectral energy\n",
    "    freqs = fftfreq(len(mag), 1/fs)\n",
    "    fft_mag = np.abs(fft(mag))[:len(mag)//2]\n",
    "    pos_freqs = freqs[:len(mag)//2]\n",
    "    dominant_freq = pos_freqs[np.argmax(fft_mag)] if len(fft_mag) > 0 else 0\n",
    "    spectral_energy = np.sum(fft_mag**2)\n",
    "    f += [dominant_freq, spectral_energy]\n",
    "\n",
    "    # 18-20: cross-axis correlations\n",
    "    f.append(np.corrcoef(ax, ay)[0, 1] if np.std(ax) > 0 and np.std(ay) > 0 else 0)\n",
    "    f.append(np.corrcoef(ay, az)[0, 1] if np.std(ay) > 0 and np.std(az) > 0 else 0)\n",
    "    f.append(np.corrcoef(ax, az)[0, 1] if np.std(ax) > 0 and np.std(az) > 0 else 0)\n",
    "\n",
    "    # 21: max jerk\n",
    "    jerk = np.diff(mag) * fs\n",
    "    f.append(np.max(np.abs(jerk)) if len(jerk) > 0 else 0)\n",
    "\n",
    "    # 22: acceleration variance\n",
    "    f.append(np.var(mag))\n",
    "\n",
    "    assert len(f) == 23, f'Feature count mismatch: {len(f)}'\n",
    "    return np.array(f, dtype=np.float32)\n",
    "\n",
    "FEATURE_NAMES = [\n",
    "    'mean_ax','mean_ay','mean_az',\n",
    "    'std_ax','std_ay','std_az',\n",
    "    'min_mag','max_mag','range_mag',\n",
    "    'rms_ax','rms_ay','rms_az',\n",
    "    'skewness','kurtosis',\n",
    "    'zero_cross','SMA',\n",
    "    'dom_freq','spectral_energy',\n",
    "    'corr_xy','corr_yz','corr_xz',\n",
    "    'max_jerk','acc_variance'\n",
    "]\n",
    "print(f'Feature count: {len(FEATURE_NAMES)}')\n",
    "print(FEATURE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(df: pd.DataFrame, win=WINDOW_SIZE, step=STEP_SIZE):\n",
    "    \"\"\"Segment data into windows and extract features.\"\"\"\n",
    "    X, y = [], []\n",
    "    cols = ['ax','ay','az','gx','gy','gz']\n",
    "    # Group by file to avoid cross-file windows\n",
    "    groups = df.groupby('file') if 'file' in df.columns else [(None, df)]\n",
    "    for _, grp in groups:\n",
    "        data   = grp[cols].values.astype(np.float32)\n",
    "        labels = grp['label'].values\n",
    "        for start in range(0, len(data) - win, step):\n",
    "            window = data[start:start+win]\n",
    "            label  = int(labels[start:start+win].mean() > 0.5)\n",
    "            X.append(extract_23_features(window))\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print('Extracting features from sliding windows...')\n",
    "X, y = sliding_windows(raw)\n",
    "print(f'Windows: {len(X):,}  |  Features: {X.shape[1]}')\n",
    "print(f'Class balance â€” Fall: {y.sum():,} ({y.mean()*100:.1f}%)  ADL: {(y==0).sum():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=12, min_samples_leaf=2,\n",
    "    class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf.fit(X_train_s, y_train)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(rf, X_train_s, y_train, cv=5, scoring='f1')\n",
    "print(f'CV F1:  {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test_s)\n",
    "y_prob = rf.predict_proba(X_test_s)[:, 1]\n",
    "\n",
    "print(f'=== {PLACEMENT} Mode â€” Test Results ===')\n",
    "print(classification_report(y_test, y_pred, target_names=['ADL','FALL']))\n",
    "\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(f'AUC-ROC: {auc:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['ADL','FALL'], yticklabels=['ADL','FALL'])\n",
    "plt.title(f'{PLACEMENT} â€” Confusion Matrix')\n",
    "plt.ylabel('True'); plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'models/{PLACEMENT}_confusion.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = pd.Series(rf.feature_importances_, index=FEATURE_NAMES).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,5))\n",
    "importances.plot(kind='bar', color='steelblue')\n",
    "plt.title(f'{PLACEMENT} â€” Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'models/{PLACEMENT}_importance.png', dpi=150)\n",
    "plt.show()\n",
    "print('Top 5 features:')\n",
    "print(importances.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path  = f'models/{PLACEMENT}_rf_model.pkl'\n",
    "scaler_path = f'models/{PLACEMENT}_scaler.pkl'\n",
    "joblib.dump(rf,     model_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f'Saved: {model_path}')\n",
    "print(f'Saved: {scaler_path}')\n",
    "\n",
    "# Save results summary for Evaluation notebook\n",
    "results = {\n",
    "    'placement': PLACEMENT,\n",
    "    'dataset':   'SisFall',\n",
    "    'n_windows': len(X),\n",
    "    'cv_f1_mean': cv_scores.mean(),\n",
    "    'cv_f1_std':  cv_scores.std(),\n",
    "    'auc': auc,\n",
    "}\n",
    "pd.DataFrame([results]).to_csv(f'models/{PLACEMENT}_results.csv', index=False)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
